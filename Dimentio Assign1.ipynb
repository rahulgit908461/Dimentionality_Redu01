{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d361bba7-3096-4e2f-a967-7657c366ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is the curse of dimensionality reduction and why is it important in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93910b7f-5de3-4538-9982-8508e0bb3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The curse of dimensionality basically refers to the difficulties a machine learning algorithm faces when working\n",
    "#with data in the higher dimensions, that did not exist in the lower dimensions. This happens because when you add \n",
    "#dimensions (features), the minimum data requirements also increase rapidly.\n",
    "#we would need more number of data points for any given combination of features, for any machine learning model \n",
    "#to be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85f9548-caf8-464d-8d4c-ea1c01b08ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How does the curse of dimensionality impact the performance of machine learning algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154584b2-4c71-47ca-8fa4-abec50fb70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The curse of dimensionality basically refers to the difficulties a machine learning algorithm faces when working\n",
    "#with data in the higher dimensions, that did not exist in the lower dimensions. This happens because when you add\n",
    "#dimensions (features), the minimum data requirements also increase rapidly.\n",
    "#As the dimensionality increases, the number of data points required for good performance of any machine learning \n",
    "#algorithm increases exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329dc370-47ae-4228-adde-9cad0b27ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What are some of the consequences of the curse of dimensionality in machine learning, and how do\n",
    "#they impact model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce502f81-04a5-4743-bd81-bbf1f82cbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The curse of dimensionality basically refers to the difficulties a machine learning algorithm faces when working \n",
    "#with data in the higher dimensions, that did not exist in the lower dimensions. This happens because when you add\n",
    "#dimensions (features), the minimum data requirements also increase rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d466cb4-6536-428b-bf32-18a7477f531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Can you explain the concept of feature selection and how it can help with dimensionality reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82656d45-74a2-4928-8763-499bb5b704a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While both methods are used for reducing the number of features in a dataset, there is an important difference. \n",
    "#Feature selection is simply selecting and excluding given features without changing them. Dimensionality\n",
    "#reduction transforms features into a lower dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f849d4-b01a-4794-b9f2-3f21e6cb1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are some limitations and drawbacks of using dimensionality reduction techniques in machine\n",
    "#learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a9ecfe-1955-43b1-a1b2-dd22c336ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the disadvantages of Dimensionality reduction are as follows:\n",
    "#While doing dimensionality reduction, we lost some of the information, which can possibly affect the \n",
    "#performance of subsequent training algorithms.\n",
    "#It can be computationally intensive.\n",
    "#Transformed features are often hard to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79724157-b8ac-48b3-859e-74242bee63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How does the curse of dimensionality relate to overfitting and underfitting in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73851212-a173-4bb1-adf8-444fddc8beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN is very susceptible to overfitting due to the curse of dimensionality. Curse of dimensionality also describes\n",
    "#the phenomenon where the feature space becomes increasingly sparse for an increasing number of dimensions of a \n",
    "#fixed-size training dataset.\n",
    "#as the number of features increase, our data become sparser, which results in overfitting, and we therefore need\n",
    "#more data to avoid it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3be23d5-7bd5-4354-958b-93bc140173d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. How can one determine the optimal number of dimensions to reduce data to when using\n",
    "#dimensionality reduction techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978e993-d7e7-45a0-8d08-08549b39fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The various techniques used for dimensionality reduction include:\n",
    "Principal Component Analysis (PCA)\n",
    "Linear Discriminant Analysis (LDA)\n",
    "Generalized Discriminant Analysis (GDA)\n",
    "Multi-Dimension Scaling (MDS)\n",
    "LLE.\n",
    "IsoMap.\n",
    "Autoencoders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
